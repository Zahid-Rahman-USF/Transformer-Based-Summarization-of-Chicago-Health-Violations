{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["lR9Dqqdjtp3z","NuARp5x_2ODq","mwsyEZhmthg2"],"authorship_tag":"ABX9TyPR/h7/5fnyW2hzmcuMsvFJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"76a218d824dd4696b1530f5ad24f2a27":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_458052c39b5b4a89b755249808bb5091","IPY_MODEL_6ff2797a721f4f1d9338d914dbf2e9c4","IPY_MODEL_0a16365756f842d981bce481e49e1dc7"],"layout":"IPY_MODEL_27c98b46bb4c4fa698e20c0a5806872b"}},"458052c39b5b4a89b755249808bb5091":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b8fde468e504409a71dde98f9c1747c","placeholder":"​","style":"IPY_MODEL_15418d029e7844eaa08a55d631c0f405","value":"Generating keywords:   0%"}},"6ff2797a721f4f1d9338d914dbf2e9c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4248510155245ecaf5945a76c3f6d5f","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7ec2b08023d45af9be3828585df65f3","value":0}},"0a16365756f842d981bce481e49e1dc7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_147a4b0852dd4f9699353ef63da3d8e9","placeholder":"​","style":"IPY_MODEL_3b82fa9acafa44e6a9bdcb11b873f464","value":" 0/100 [00:01&lt;?, ?it/s]"}},"27c98b46bb4c4fa698e20c0a5806872b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b8fde468e504409a71dde98f9c1747c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15418d029e7844eaa08a55d631c0f405":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4248510155245ecaf5945a76c3f6d5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7ec2b08023d45af9be3828585df65f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"147a4b0852dd4f9699353ef63da3d8e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b82fa9acafa44e6a9bdcb11b873f464":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b410ed94553747f5b813b53b55030dad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_965aaf4a140646a8955237cf62415311","IPY_MODEL_973e2aa7cdcd48df8c1d4fe3932b7d7c","IPY_MODEL_c28a49a58f514a4b816228a340de5d78"],"layout":"IPY_MODEL_c30f7c672e584186ac30de1c0def09e4"}},"965aaf4a140646a8955237cf62415311":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26a2e2eec5794149a0540c0f1b5c2007","placeholder":"​","style":"IPY_MODEL_35ebaea463934cc1aaafb7d54fae9675","value":"Evaluating keywords: 100%"}},"973e2aa7cdcd48df8c1d4fe3932b7d7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9efd140164641f181a4a14258c22de3","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a11508c91d444c1ad4b7db2278dd61a","value":100}},"c28a49a58f514a4b816228a340de5d78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cd29a96088541cba6838cb15df8f5ea","placeholder":"​","style":"IPY_MODEL_49320578df8a41e4a56e621db982c8cf","value":" 100/100 [02:24&lt;00:00,  1.53s/it]"}},"c30f7c672e584186ac30de1c0def09e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26a2e2eec5794149a0540c0f1b5c2007":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35ebaea463934cc1aaafb7d54fae9675":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9efd140164641f181a4a14258c22de3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a11508c91d444c1ad4b7db2278dd61a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7cd29a96088541cba6838cb15df8f5ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49320578df8a41e4a56e621db982c8cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c47f02d936a4e5d86f10cbbf7ba660a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c26b6b2fccdb4b9296956d02b6f29af5","IPY_MODEL_f355adbd49e1464ba267909870de602b","IPY_MODEL_d8dd27be7ebe4451a8c7956933aada01"],"layout":"IPY_MODEL_6ea4cec204f3425f85b856b0123aae21"}},"c26b6b2fccdb4b9296956d02b6f29af5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_088d9161b2cc4bbca05c6c53a7d83cd5","placeholder":"​","style":"IPY_MODEL_dec6e55b323a4af0aaca29b87964c721","value":"Map: 100%"}},"f355adbd49e1464ba267909870de602b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3db72ff45f84ad7b998c077c8fb5ced","max":2466,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dcd04714146a48ae91f20f96fe4a18b2","value":2466}},"d8dd27be7ebe4451a8c7956933aada01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca68071126f84534bd74cc7dac892ee0","placeholder":"​","style":"IPY_MODEL_4835dbedf17a427695fc304ee0a9f90a","value":" 2466/2466 [00:02&lt;00:00, 1041.32 examples/s]"}},"6ea4cec204f3425f85b856b0123aae21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"088d9161b2cc4bbca05c6c53a7d83cd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dec6e55b323a4af0aaca29b87964c721":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3db72ff45f84ad7b998c077c8fb5ced":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcd04714146a48ae91f20f96fe4a18b2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca68071126f84534bd74cc7dac892ee0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4835dbedf17a427695fc304ee0a9f90a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78a2a7478ac74e21b01391e3ce7c1232":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_17385e3b9a2b440f9a381045a53a01e9","IPY_MODEL_3acb6d9a6a8e4bb7bdd941461e6e1d3b","IPY_MODEL_9d316650275640f7ac25f77b5cc72328"],"layout":"IPY_MODEL_7193a98ec33a4858a54d492e775651c4"}},"17385e3b9a2b440f9a381045a53a01e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9b57ccf86ca40b6836b91ed9f130bcc","placeholder":"​","style":"IPY_MODEL_47e8c7b27e9c4432a7c2615e29ec23cf","value":"Map: 100%"}},"3acb6d9a6a8e4bb7bdd941461e6e1d3b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4dae99dcd2345439b2fee586cec06f9","max":297,"min":0,"orientation":"horizontal","style":"IPY_MODEL_281a3eaee34e4265988bfa8b1627339f","value":297}},"9d316650275640f7ac25f77b5cc72328":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0632eca5f0b54285b8a443ba954e98e7","placeholder":"​","style":"IPY_MODEL_4e4cbe87cfc34aef8ed39dc18a40b9d0","value":" 297/297 [00:00&lt;00:00, 1000.92 examples/s]"}},"7193a98ec33a4858a54d492e775651c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9b57ccf86ca40b6836b91ed9f130bcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47e8c7b27e9c4432a7c2615e29ec23cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4dae99dcd2345439b2fee586cec06f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"281a3eaee34e4265988bfa8b1627339f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0632eca5f0b54285b8a443ba954e98e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e4cbe87cfc34aef8ed39dc18a40b9d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"715e21bfe2434c35b1477948ed738ec9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c3cbed25b3e54592ad67a70ef6c09c3b","IPY_MODEL_af46bc6f64ba44f3a8c31b680f634475","IPY_MODEL_c1dbba7326514920b44e454c80f6429a"],"layout":"IPY_MODEL_9bbb2a13be3540a29e3a899f0eb3aae0"}},"c3cbed25b3e54592ad67a70ef6c09c3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4299ee456a14f708db882dac31f1961","placeholder":"​","style":"IPY_MODEL_4937258cd74942ddb948875f539457c0","value":"Map: 100%"}},"af46bc6f64ba44f3a8c31b680f634475":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_37c7599111dd4b579b4219b72de82c84","max":300,"min":0,"orientation":"horizontal","style":"IPY_MODEL_20bad3bb746546c2bf6b03e9472ccd39","value":300}},"c1dbba7326514920b44e454c80f6429a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eaec4e06dd6b42f6b22b8871bd592982","placeholder":"​","style":"IPY_MODEL_335929e60adc4cd2a194f9db5757de96","value":" 300/300 [00:00&lt;00:00, 995.77 examples/s]"}},"9bbb2a13be3540a29e3a899f0eb3aae0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4299ee456a14f708db882dac31f1961":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4937258cd74942ddb948875f539457c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37c7599111dd4b579b4219b72de82c84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20bad3bb746546c2bf6b03e9472ccd39":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eaec4e06dd6b42f6b22b8871bd592982":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"335929e60adc4cd2a194f9db5757de96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"628dfb7a0081459280064345babb278b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_58899fc5ab4041759b69843626c4b7cd","IPY_MODEL_1f464fd2266045738e211de4d1675a0f","IPY_MODEL_12a0af62c3d04f04b4ce44692d8d2912"],"layout":"IPY_MODEL_92d275d3c69e4841a08443a848355523"}},"58899fc5ab4041759b69843626c4b7cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a92a98a9e9bb4b6aa13a308205542432","placeholder":"​","style":"IPY_MODEL_c869f80387804ed985f6fbcd6ad44556","value":"Running inference: 100%"}},"1f464fd2266045738e211de4d1675a0f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0c09f7261464a2991489ea068d3610d","max":19,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d6ba9fba4fe4dd58bb900592200ae38","value":19}},"12a0af62c3d04f04b4ce44692d8d2912":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4780bec6cb149fa80d3f5d2e9187a19","placeholder":"​","style":"IPY_MODEL_4f7b136bcb534e1da3e279906f87452e","value":" 19/19 [03:09&lt;00:00,  9.94s/it]"}},"92d275d3c69e4841a08443a848355523":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a92a98a9e9bb4b6aa13a308205542432":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c869f80387804ed985f6fbcd6ad44556":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0c09f7261464a2991489ea068d3610d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d6ba9fba4fe4dd58bb900592200ae38":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4780bec6cb149fa80d3f5d2e9187a19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f7b136bcb534e1da3e279906f87452e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Executive Summary\n","\n","- **Project Goal**  \n","  Build a local, quantized Transformer that ingests raw health-inspection violations and returns a structured JSON object with two fields:  \n","  1. **summary**: a 1–2 sentence consumer-friendly verdict ending in one of four canned food-safety statements  \n","  2. **keywords**: a list of 3–7 lowercase issue tags  \n","\n","- **Data Preparation (Notebook1- Not this one)**  \n","  - Sampled 3,000 violation texts from Chicago’s API  \n","  - Used OpenAI ChatCompletion to generate training JSONL (`summary` + `keywords`)  \n","  - Split into train/val/test and augmented with synthetic “not safe” examples  \n","\n","- **Fine-Tuning (Notebook 2-This notebook)**  \n","  - Loaded `google/flan-t5-small` with 4-bit quantization and applied LoRA adapters  \n","  - Trained for 3 epochs on the JSONL data  \n","  - Saved the quantized + LoRA model for offline inference  \n","\n","- **Evaluation Attempts**  \n","  - **Plain-text metrics**: swapped to a “Summarize this…” prompt and computed ROUGE/BERTScore; saw small improvements (e.g. ROUGE-1 from ~0.13→0.15) but lost JSON structure  \n","  - **JSON-parsing metrics**: tried to parse model outputs back into JSON and score summaries/keywords; scores stayed at zero because the inference prompt didn’t match training  \n","  - **Debugging**: re-loaded models correctly, batched inference with progress bars, handled malformed outputs—nothing overcame the prompt-mismatch issue  \n","\n","- **Key Insight**  \n","  The fine-tuned model only emits valid JSON when given the exact same instruction it saw during training. Any deviation (e.g. plain summarization prompt) collapses to empty or gibberish outputs, making robust metric computation impossible without re-training.\n","\n","- **Next Steps: Web Integration**  \n","  - Deploy the quantized + LoRA model in the backend  \n","  - At inference, prepend the original JSON-generation prompt to each violation text  \n","  - Parse `summary` + `keywords` from the returned JSON and serve to the frontend  \n","  - Defer deeper offline metric refinement until after integration, since end-to-end functionality is now validated and cost-free (no API calls)\n"],"metadata":{"id":"oTEeFcndgeRH"}},{"cell_type":"markdown","source":["# Refined Code (1st Run)"],"metadata":{"id":"lR9Dqqdjtp3z"}},{"cell_type":"code","source":["# Block A: Imports & Environment Setup\n","\n","# Install necessary libraries\n","!pip install transformers datasets peft bitsandbytes accelerate evaluate -q\n","\n","# Disable Weights & Biases logging\n","import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","# Core imports\n","import torch\n","import pandas as pd\n","from datasets import load_dataset, DatasetDict\n","from transformers import (\n","    AutoTokenizer,\n","    T5ForConditionalGeneration,\n","    BitsAndBytesConfig,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq\n",")\n","from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n","from tqdm.auto import tqdm\n","import evaluate\n","import json\n","\n","# Check environment\n","print(f\"PyTorch version: {torch.__version__}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nh59Zz7stqJw","executionInfo":{"status":"ok","timestamp":1745637228730,"user_tz":240,"elapsed":2645,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"ae8c1141-dc5d-4a8e-d9d3-7ef439c5c04d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch version: 2.6.0+cu124\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","data_files = {\n","    \"train\": \"violations_train_final.jsonl\",\n","    \"validation\": \"violations_val.jsonl\",\n","    \"test\": \"violations_test.jsonl\"\n","}\n","\n","data = load_dataset(\"json\", data_files=data_files)\n","\n","# Inspect the dataset\n","print(data)\n","print(\"\\nSample training example:\")\n","print(data[\"train\"][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZdAtCmLvQe3","executionInfo":{"status":"ok","timestamp":1745637231376,"user_tz":240,"elapsed":710,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"fd14063f-6ade-4db4-893a-fff3519a2d84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['violation', 'summary', 'keywords'],\n","        num_rows: 2466\n","    })\n","    validation: Dataset({\n","        features: ['violation', 'summary', 'keywords'],\n","        num_rows: 297\n","    })\n","    test: Dataset({\n","        features: ['violation', 'summary', 'keywords'],\n","        num_rows: 300\n","    })\n","})\n","\n","Sample training example:\n","{'violation': '32. FOOD AND NON-FOOD CONTACT SURFACES PROPERLY DESIGNED, CONSTRUCTED AND MAINTAINED - Comments: All food and non-food contact equipment and utensils shall be smooth, easily cleanable, and durable, and shall be in good repair. MUST CLEAN AND MAINTAIN THE FOLLOWING: FAN GUARD COVERS OF WALK-IN COOLER TO REMOVE DUST OBSERVED, BOTTOM OF FRYERS TO REMOVE DUST AND GREASE, INTERIOR OF FREEZER AT GRILL AREA, SURFACE AREA ABOVE HOT UNIT WHERE FRENCH FRIES HELD. | 34. FLOORS: CONSTRUCTED PER CODE, CLEANED, GOOD REPAIR, COVING INSTALLED, DUST-LESS CLEANING METHODS USED - Comments: VIOLATION PARTIALLY CORRECTED.    REPLACE MISSING FLOOR TILE NEAR SIDE OF GRILL FILLED WITH WATER. (TILE WAS ORDERED) | 35. WALLS, CEILINGS, ATTACHED EQUIPMENT CONSTRUCTED PER CODE: GOOD REPAIR, SURFACES CLEAN AND DUST-LESS CLEANING METHODS - Comments: The walls and ceilings shall be in good repair and easily cleaned. REPLACE MISSING OR CRACKED WALL TILE AT BASE OF WALL IN OFFICE AND BY EXPOSED HANDSINK. SEAL HOLES AROUND PIPES OF TOILETS IN BOTH WASHROOMS AND IN WALLS OF BOTH WASHROOMS WHERE SENSOR USED TO BE. REPLACE ANY STAINED CEILING TILES WHERE NEEDED.', 'summary': 'The inspection revealed several maintenance issues related to cleanliness and repair of surfaces and equipment. This violation is not related to food safety.', 'keywords': ['cleanliness', 'maintenance', 'surfaces', 'equipment', 'repair']}\n"]}]},{"cell_type":"code","source":["# 2. Tokenizer\n","model_name = \"google/flan-t5-small\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","\n","# 3. Preprocessing Function\n","max_input_length = 512\n","max_target_length = 128\n","\n","def preprocess_fn(examples):\n","    inputs = tokenizer(\n","        examples[\"violation\"],\n","        max_length=max_input_length,\n","        truncation=True,\n","        padding=\"max_length\"\n","    )\n","    targets = [\n","        json.dumps({\"summary\": s, \"keywords\": k})\n","        for s, k in zip(examples[\"summary\"], examples[\"keywords\"])\n","    ]\n","    with tokenizer.as_target_tokenizer():\n","        tokenized_targets = tokenizer(\n","            targets,\n","            max_length=max_target_length,\n","            truncation=True,\n","            padding=\"max_length\"\n","        )\n","    # mask pad tokens as -100\n","    labels = [\n","        [(tok if tok != tokenizer.pad_token_id else -100) for tok in seq]\n","        for seq in tokenized_targets[\"input_ids\"]\n","    ]\n","    inputs[\"labels\"] = labels\n","    return inputs\n","\n","# 4. Apply Tokenization\n","tokenized = data.map(\n","    preprocess_fn,\n","    batched=True,\n","    remove_columns=data[\"train\"].column_names\n",")\n","\n","# 5. Quantization + LoRA Setup\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16  # A100-friendly\n",")\n","base_model = T5ForConditionalGeneration.from_pretrained(\n","    model_name,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\",\n","    trust_remote_code=True\n",")\n","model = prepare_model_for_kbit_training(base_model)\n","\n","lora_config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"SEQ_2_SEQ_LM\"\n",")\n","model = get_peft_model(model, lora_config)\n","\n","# 6. Data Collator\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","# 7. Training Arguments (use BF16, disable FP16)\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"flan_t5_small_lora\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    gradient_accumulation_steps=1,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    logging_strategy=\"steps\",\n","    logging_steps=50,\n","    num_train_epochs=3,\n","    learning_rate=2e-5,\n","    bf16=True,\n","    fp16=False,\n","    push_to_hub=False,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_loss\",\n","    save_total_limit=2\n",")\n","\n","# 8. Sanity Check: single‐example forward‐pass\n","batch = data_collator([ tokenized[\"train\"][0] ])\n","batch = {k: v.to(next(model.parameters()).device) for k, v in batch.items()}\n","out = model(**batch)\n","print(\"sanity loss:\", out.loss)  # should be finite (e.g. ~3–5)\n","\n","# 9. Trainer Instantiation\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized[\"train\"],\n","    eval_dataset=tokenized[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer\n",")\n","\n","# 10. Training & Evaluation\n","trainer.train()\n","print(\"Validation metrics:\", trainer.evaluate(tokenized[\"validation\"]))\n","print(\"Test metrics:\",       trainer.evaluate(tokenized[\"test\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":566,"referenced_widgets":["8c47f02d936a4e5d86f10cbbf7ba660a","c26b6b2fccdb4b9296956d02b6f29af5","f355adbd49e1464ba267909870de602b","d8dd27be7ebe4451a8c7956933aada01","6ea4cec204f3425f85b856b0123aae21","088d9161b2cc4bbca05c6c53a7d83cd5","dec6e55b323a4af0aaca29b87964c721","e3db72ff45f84ad7b998c077c8fb5ced","dcd04714146a48ae91f20f96fe4a18b2","ca68071126f84534bd74cc7dac892ee0","4835dbedf17a427695fc304ee0a9f90a","78a2a7478ac74e21b01391e3ce7c1232","17385e3b9a2b440f9a381045a53a01e9","3acb6d9a6a8e4bb7bdd941461e6e1d3b","9d316650275640f7ac25f77b5cc72328","7193a98ec33a4858a54d492e775651c4","f9b57ccf86ca40b6836b91ed9f130bcc","47e8c7b27e9c4432a7c2615e29ec23cf","c4dae99dcd2345439b2fee586cec06f9","281a3eaee34e4265988bfa8b1627339f","0632eca5f0b54285b8a443ba954e98e7","4e4cbe87cfc34aef8ed39dc18a40b9d0","715e21bfe2434c35b1477948ed738ec9","c3cbed25b3e54592ad67a70ef6c09c3b","af46bc6f64ba44f3a8c31b680f634475","c1dbba7326514920b44e454c80f6429a","9bbb2a13be3540a29e3a899f0eb3aae0","e4299ee456a14f708db882dac31f1961","4937258cd74942ddb948875f539457c0","37c7599111dd4b579b4219b72de82c84","20bad3bb746546c2bf6b03e9472ccd39","eaec4e06dd6b42f6b22b8871bd592982","335929e60adc4cd2a194f9db5757de96"]},"id":"kypGdqPGFXCf","executionInfo":{"status":"ok","timestamp":1745637503245,"user_tz":240,"elapsed":265009,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"5caf73d3-ad54-4820-c937-4e49a24234e5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2466 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c47f02d936a4e5d86f10cbbf7ba660a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/297 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78a2a7478ac74e21b01391e3ce7c1232"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/300 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"715e21bfe2434c35b1477948ed738ec9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","<ipython-input-40-f0a605058128>:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n","  trainer = Seq2SeqTrainer(\n","No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["sanity loss: tensor(3.4256, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='927' max='927' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [927/927 04:13, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>3.318500</td>\n","      <td>2.830792</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.818700</td>\n","      <td>2.299953</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>2.651500</td>\n","      <td>2.164483</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='76' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [38/38 00:05]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Validation metrics: {'eval_loss': 2.1644833087921143, 'eval_runtime': 2.8037, 'eval_samples_per_second': 105.931, 'eval_steps_per_second': 13.553, 'epoch': 3.0}\n","Test metrics: {'eval_loss': 2.1573050022125244, 'eval_runtime': 2.8054, 'eval_samples_per_second': 106.938, 'eval_steps_per_second': 13.546, 'epoch': 3.0}\n"]}]},{"cell_type":"code","source":["# ─── Quick Evaluation: Plain-Text Summaries Only ───────────────────────────\n","\n","# 1. Install & imports (if not already done)\n","!pip install rouge_score evaluate bert_score --quiet\n","\n","import pandas as pd\n","import evaluate\n","from transformers import T5ForConditionalGeneration\n","\n","# 2. Load metrics\n","rouge = evaluate.load(\"rouge\")\n","berts = evaluate.load(\"bertscore\")\n","\n","# 3. Prepare test data\n","violations = data[\"test\"][\"violation\"]\n","references = data[\"test\"][\"summary\"]   # your 1–2 sentence refs\n","\n","# 4. Generation helper (plain summaries)\n","def generate_summaries(model, tokenizer, texts,\n","                       batch_size=16, max_new=128, min_len=20):\n","    model.eval()\n","    outs = []\n","    for i in range(0, len(texts), batch_size):\n","        chunk = texts[i : i + batch_size]\n","        enc = tokenizer(\n","            [\"Summarize this inspection violation:\\n\\n\" + t for t in chunk],\n","            return_tensors=\"pt\",\n","            truncation=True,\n","            padding=True\n","        ).to(model.device)\n","        gen = model.generate(\n","            **enc,\n","            max_new_tokens=max_new,\n","            min_length=min_len,\n","            num_beams=4,\n","            early_stopping=True\n","        )\n","        decs = tokenizer.batch_decode(gen, skip_special_tokens=True)\n","        outs.extend([d.strip() for d in decs])\n","    return outs\n","\n","# 5. Load your two models\n","base_model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\").to(model.device)\n","ft_model   = model   # the LoRA-fine-tuned model you just trained\n","\n","# 6. Generate summaries\n","print(\"Generating with base model…\")\n","base_summaries = generate_summaries(base_model, tokenizer, violations)\n","print(\"Generating with fine-tuned model…\")\n","ft_summaries   = generate_summaries(ft_model,   tokenizer, violations)\n","\n","# 7. Sanity-check a few\n","for i in range(3):\n","    print(f\"[{i}] BASE :\", repr(base_summaries[i]))\n","    print(f\"[{i}] F-T  :\", repr(ft_summaries[i]))\n","    print(f\"[{i}] REF  :\", repr(references[i]))\n","    print(\"---\")\n","\n","# 8. Compute metrics\n","r_base = rouge.compute(predictions=base_summaries, references=references)\n","r_ft   = rouge.compute(predictions=ft_summaries,   references=references)\n","b_base = bermodel = berts.compute(predictions=base_summaries,\n","                                  references=references,\n","                                  model_type=\"microsoft/deberta-xlarge-mnli\")\n","b_ft   = berts.compute(predictions=ft_summaries,\n","                       references=references,\n","                       model_type=\"microsoft/deberta-xlarge-mnli\")\n","\n","# 9. Aggregate & show\n","df = pd.DataFrame([\n","    {\n","      \"model\":\"Base\",\n","      \"rouge1\": r_base[\"rouge1\"],\n","      \"rouge2\": r_base[\"rouge2\"],\n","      \"rougeL\": r_base[\"rougeL\"],\n","      \"bertscore\": sum(b_base[\"f1\"])/len(b_base[\"f1\"])\n","    },\n","    {\n","      \"model\":\"Fine-tuned\",\n","      \"rouge1\": r_ft[\"rouge1\"],\n","      \"rouge2\": r_ft[\"rouge2\"],\n","      \"rougeL\": r_ft[\"rougeL\"],\n","      \"bertscore\": sum(b_ft[\"f1\"])/len(b_ft[\"f1\"])\n","    }\n","]).set_index(\"model\")\n","\n","from IPython.display import display\n","display(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":493},"id":"vwK1r12YIufy","executionInfo":{"status":"ok","timestamp":1745641834875,"user_tz":240,"elapsed":149574,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"3abbda23-c6f9-4b62-d537-910acc51c120"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generating with base model…\n","Generating with fine-tuned model…\n","[0] BASE : 'DISAPPOINTMENT DURING FOOD PREPARATION, STORAGE & DISPLAY - Comments: 4-101.19 : MUST ELIMINATE CRATES USED FOR FOOD STORAGE IN DRY FOOD & PAPER STORAGE AREA AND WALK IN COOLER'\n","[0] F-T  : 'The inspection violation is a violation of food safety regulations, including food safety, and food safety, and food safety.'\n","[0] REF  : 'The inspection revealed issues with food storage practices that could lead to contamination. This violation is related to food safety and may make it unsafe to eat here.'\n","---\n","[1] BASE : '#32 CLEAN AND MAINTAIN ALL BUTCHER EQUIPMENT; GRINDERS, MEAT SAWS ETC. #34 CLEAN FLOOR DRAIN IN BUTCHER PREP AREA TO REMOVE DEBIS OBSERVED INSIDE'\n","[1] F-T  : ''\n","[1] REF  : 'The inspection revealed several serious violations, including unsanitary conditions and evidence of pest activity, which may pose a risk to food safety. This violation is related to food safety and may make it unsafe to eat here.'\n","---\n","[2] BASE : 'DISAPPOINTMENT - CONSTRUCTION - CONSTRUCTION - CONSTRUCTION - CONSTRUCTION - CONSTRUCTION - CONSTRUCTION'\n","[2] F-T  : 'The inspection was deemed to be a violation of the sanitary conditions of the building. The inspection was deemed to be a violation of the sanitary conditions.'\n","[2] REF  : 'The inspection revealed several maintenance issues, including gaps in doors and damaged surfaces, which could potentially lead to pest entry and sanitation concerns. This violation is related to food safety, but it is safe to eat here.'\n","---\n"]},{"output_type":"stream","name":"stderr","text":["Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"]},{"output_type":"display_data","data":{"text/plain":["              rouge1    rouge2    rougeL  bertscore\n","model                                              \n","Base        0.128822  0.031743  0.100526   0.465304\n","Fine-tuned  0.155449  0.037242  0.121641   0.434560"],"text/html":["\n","  <div id=\"df-ea0456f9-f391-4e07-b394-2c916957a3fc\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rouge1</th>\n","      <th>rouge2</th>\n","      <th>rougeL</th>\n","      <th>bertscore</th>\n","    </tr>\n","    <tr>\n","      <th>model</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Base</th>\n","      <td>0.128822</td>\n","      <td>0.031743</td>\n","      <td>0.100526</td>\n","      <td>0.465304</td>\n","    </tr>\n","    <tr>\n","      <th>Fine-tuned</th>\n","      <td>0.155449</td>\n","      <td>0.037242</td>\n","      <td>0.121641</td>\n","      <td>0.434560</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea0456f9-f391-4e07-b394-2c916957a3fc')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ea0456f9-f391-4e07-b394-2c916957a3fc button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ea0456f9-f391-4e07-b394-2c916957a3fc');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-0845e2fa-7251-49c2-885c-8cf79413e282\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0845e2fa-7251-49c2-885c-8cf79413e282')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-0845e2fa-7251-49c2-885c-8cf79413e282 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_69f19367-b01e-4cbe-b35d-e8c8404d56be\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_69f19367-b01e-4cbe-b35d-e8c8404d56be button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Fine-tuned\",\n          \"Base\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.018827639332255258,\n        \"min\": 0.12882242034234462,\n        \"max\": 0.15544872323348913,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.15544872323348913,\n          0.12882242034234462\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0038886610560073037,\n        \"min\": 0.03174286975398595,\n        \"max\": 0.03724226695886356,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.03724226695886356,\n          0.03174286975398595\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01493052927480511,\n        \"min\": 0.10052620970199624,\n        \"max\": 0.12164116669583416,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.12164116669583416,\n          0.10052620970199624\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bertscore\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02173899924410748,\n        \"min\": 0.43456042086084684,\n        \"max\": 0.4653040084242821,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.43456042086084684,\n          0.4653040084242821\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"code","source":["# 1. Save the fine-tuned model & tokenizer\n","model.save_pretrained(\"flan_t5_small_plain_lora\")\n","tokenizer.save_pretrained(\"flan_t5_small_plain_lora\")\n","\n","# 2. (Optional) zip the folder for easy download/storage\n","!zip -r flan_t5_small_plain_lora.zip flan_t5_small_plain_lora"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZGG7LPpiXmn4","executionInfo":{"status":"ok","timestamp":1745642034914,"user_tz":240,"elapsed":1049,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"ef9f5640-7d66-4038-de75-6948a04e658d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: flan_t5_small_plain_lora/ (stored 0%)\n","  adding: flan_t5_small_plain_lora/spiece.model (deflated 48%)\n","  adding: flan_t5_small_plain_lora/special_tokens_map.json (deflated 85%)\n","  adding: flan_t5_small_plain_lora/tokenizer_config.json (deflated 95%)\n","  adding: flan_t5_small_plain_lora/README.md (deflated 66%)\n","  adding: flan_t5_small_plain_lora/tokenizer.json (deflated 74%)\n","  adding: flan_t5_small_plain_lora/adapter_model.safetensors (deflated 7%)\n","  adding: flan_t5_small_plain_lora/adapter_config.json (deflated 54%)\n"]}]},{"cell_type":"markdown","source":["# Refined Code (Loading Model in-2nd Run)"],"metadata":{"id":"NuARp5x_2ODq"}},{"cell_type":"markdown","source":["The Core Issue\n","Train‐time inputs: \"<RAW_VIOLATION_TEXT>\"\n","\n","Train‐time target: {\"summary\":…, \"keywords\":[…]}\n","\n","Eval‐time inputs: \"<RAW_VIOLATION_TEXT>\" (no prefix)\n","\n","Eval‐time tried: also tried \"Summarize this…” + text\n","\n","In both cases it didn’t see the big JSON‐instruction at inference the way it did in training, so it just loops or outputs nothing."],"metadata":{"id":"LXcioxatfrNp"}},{"cell_type":"code","source":["# unzip your saved model\n","!unzip flan_t5_small_plain_lora.zip -d flan_t5_small_plain_lora"],"metadata":{"id":"2lZewRFr380m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cell 1: Installs, imports, device\n","!pip install transformers datasets peft evaluate rouge_score bert_score -q\n","\n","import torch, json\n","from transformers import BitsAndBytesConfig, T5ForConditionalGeneration, AutoTokenizer\n","from peft import PeftModel\n","import evaluate, pandas as pd\n","from datasets import load_dataset\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Cell 2: Load test data\n","data = load_dataset(\"json\", data_files={\"test\":\"violations_test.jsonl\"})\n","texts        = data[\"test\"][\"violation\"]\n","ref_summ     = data[\"test\"][\"summary\"]\n","ref_keywords = data[\"test\"][\"keywords\"]\n","\n","# Cell 3: Load quantized + LoRA model\n","bnb = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","backbone  = T5ForConditionalGeneration.from_pretrained(\n","    \"google/flan-t5-small\",\n","    quantization_config=bnb,\n","    device_map=\"auto\",\n","    trust_remote_code=True\n",")\n","model_dir = \"/content/flan_t5_small_plain_lora/flan_t5_small_plain_lora\"\n","model     = PeftModel.from_pretrained(backbone, model_dir).to(device)\n","tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","\n","# Cell 4 (updated): Inference (raw violation → JSON or list)\n","def infer_violation(vio: str):\n","    enc = tokenizer(vio, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n","    gen = model.generate(\n","        **enc,\n","        max_new_tokens=256,\n","        num_beams=4,\n","        early_stopping=True\n","    )\n","    raw = tokenizer.decode(gen[0], skip_special_tokens=True)\n","    try:\n","        obj = json.loads(raw)\n","    except json.JSONDecodeError:\n","        return {\"summary\": \"\", \"keywords\": []}\n","\n","    # If they gave a dict, great\n","    if isinstance(obj, dict):\n","        return obj\n","\n","    # If they gave a list [summary, keywords], unpack it\n","    if isinstance(obj, list) and len(obj) == 2:\n","        summary, keywords = obj\n","        return {\n","            \"summary\": summary if isinstance(summary, str) else \"\",\n","            \"keywords\": keywords if isinstance(keywords, list) else []\n","        }\n","\n","    # Otherwise fallback\n","    return {\"summary\": \"\", \"keywords\": []}\n","# Cell 5: Run inference & collect predictions (with progress bar)\n","from tqdm.auto import tqdm\n","\n","pred_summaries, pred_keywords = [], []\n","batch_size = 16\n","\n","for i in tqdm(range(0, len(texts), batch_size), desc=\"Running inference\"):\n","    batch = texts[i : i + batch_size]\n","    enc = tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n","    gens = model.generate(\n","        **enc,\n","        max_new_tokens=256,\n","        num_beams=4,\n","        early_stopping=True\n","    )\n","    raws = tokenizer.batch_decode(gens, skip_special_tokens=True)\n","    for raw in raws:\n","        try:\n","            parsed = json.loads(raw)\n","        except json.JSONDecodeError:\n","            # nothing valid → empty\n","            summary, keywords = \"\", []\n","        else:\n","            if isinstance(parsed, dict):\n","                summary  = parsed.get(\"summary\", \"\")\n","                keywords = parsed.get(\"keywords\", [])\n","            elif isinstance(parsed, list) and len(parsed) == 2:\n","                s, k = parsed\n","                summary  = s if isinstance(s, str) else \"\"\n","                keywords = k if isinstance(k, list) else []\n","            elif isinstance(parsed, str):\n","                # model returned a bare string\n","                summary, keywords = parsed, []\n","            else:\n","                summary, keywords = \"\", []\n","\n","        pred_summaries.append(summary)\n","        pred_keywords.append(keywords)\n","\n","# Cell 6: Compute and display metrics\n","# 6a) ROUGE on summaries\n","rouge        = evaluate.load(\"rouge\")\n","rouge_scores = rouge.compute(predictions=pred_summaries, references=ref_summ)\n","\n","# 6b) Set‐based F1 for keywords\n","def keyword_f1(pred, ref):\n","    p, r = set(pred), set(ref)\n","    tp   = len(p & r)\n","    return 2*tp/(len(p)+len(r)) if (p and r) else 0.0\n","\n","kw_f1s    = [keyword_f1(p, r) for p, r in zip(pred_keywords, ref_keywords)]\n","avg_kw_f1 = sum(kw_f1s) / len(kw_f1s)\n","\n","# 6c) Show results\n","df = pd.DataFrame([{\n","    \"rouge1\": rouge_scores[\"rouge1\"],\n","    \"rouge2\": rouge_scores[\"rouge2\"],\n","    \"rougeL\": rouge_scores[\"rougeL\"],\n","    \"avg_keyword_f1\": avg_kw_f1\n","}], index=[\"Fine-tuned\"])\n","\n","print(df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["628dfb7a0081459280064345babb278b","58899fc5ab4041759b69843626c4b7cd","1f464fd2266045738e211de4d1675a0f","12a0af62c3d04f04b4ce44692d8d2912","92d275d3c69e4841a08443a848355523","a92a98a9e9bb4b6aa13a308205542432","c869f80387804ed985f6fbcd6ad44556","a0c09f7261464a2991489ea068d3610d","0d6ba9fba4fe4dd58bb900592200ae38","a4780bec6cb149fa80d3f5d2e9187a19","4f7b136bcb534e1da3e279906f87452e"]},"id":"Xvm-Ezw4ZNRW","executionInfo":{"status":"ok","timestamp":1745711145762,"user_tz":240,"elapsed":195738,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"dd9ea095-5c84-498a-f5c0-66c2d4dab4d4"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["Running inference:   0%|          | 0/19 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"628dfb7a0081459280064345babb278b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["            rouge1  rouge2  rougeL  avg_keyword_f1\n","Fine-tuned     0.0     0.0     0.0             0.0\n"]}]},{"cell_type":"markdown","source":["# Original Code"],"metadata":{"id":"mwsyEZhmthg2"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","!pip install accelerate"],"metadata":{"id":"h2_cPZr-RCa_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install --upgrade transformers --quiet"],"metadata":{"id":"mAF_eICeWEcX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import transformers\n","print(transformers.__version__)  # should be ≥ 4.2.0 (ideally 4.36+)"],"metadata":{"id":"OHleN3c2WzFO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from datasets import load_dataset, Dataset, DatasetDict\n","from transformers import AutoTokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n","\n","train_path = \"/content/violations_train_with_summaries.csv\"\n","val_path   = \"/content/violations_val_with_summaries.csv\"\n","test_path  = \"/content/violations_test_with_summaries.csv\"\n","\n","# read with latin1 (or cp1252) encoding\n","train_df = pd.read_csv(train_path, encoding=\"latin-1\")\n","val_df   = pd.read_csv(val_path,   encoding=\"latin-1\")\n","test_df  = pd.read_csv(test_path,  encoding=\"latin-1\")\n","\n","data = DatasetDict({\n","    \"train\":     Dataset.from_pandas(train_df),\n","    \"validation\":Dataset.from_pandas(val_df),\n","    \"test\":      Dataset.from_pandas(test_df),\n","})\n","\n","print(data)\n"],"metadata":{"id":"e95nRUncRt30"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\""],"metadata":{"id":"EH9HePOXUilK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import (\n","    AutoTokenizer,\n","    T5ForConditionalGeneration,\n","    DataCollatorForSeq2Seq,\n","    Seq2SeqTrainer,           # ← replace Trainer\n","    Seq2SeqTrainingArguments  # ← replace TrainingArguments\n",")\n","# 1. Choose your FLAN‑T5 checkpoint\n","model_name = \"google/flan-t5-base\"\n","\n","# 2. Load tokenizer & model\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model     = T5ForConditionalGeneration.from_pretrained(model_name)\n","\n","# 3. Preprocessing function\n","max_input_length  = 512\n","max_target_length = 128\n","\n","def preprocess_fn(examples):\n","    # tokenize inputs\n","    inputs = tokenizer(\n","        examples[\"input_text\"],\n","        max_length=max_input_length,\n","        truncation=True,\n","    )\n","    # tokenize targets\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(\n","            examples[\"target_text\"],\n","            max_length=max_target_length,\n","            truncation=True,\n","        )\n","    inputs[\"labels\"] = labels[\"input_ids\"]\n","    return inputs\n","\n","# 4. Apply to all splits\n","tokenized = data.map(\n","    preprocess_fn,\n","    batched=True,\n","    remove_columns=data[\"train\"].column_names,  # drops input_text & target_text\n",")\n","\n","# 5. Prepare data collator\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","# 6. Training arguments\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"flan_t5_finetuned\",\n","    eval_strategy=\"epoch\",     # only once, spelled correctly\n","    save_strategy=\"epoch\",\n","    report_to=\"none\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_loss\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=3,\n","    learning_rate=2e-5,\n","    save_total_limit=2,\n","    logging_steps=50,\n","    predict_with_generate=True,\n",")\n","\n","# 7. Instantiate Trainer\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized[\"train\"],\n","    eval_dataset=tokenized[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n",")\n","\n","# 8. Start fine‑tuning\n","trainer.train()\n","\n","# 9. Evaluate on test set\n","metrics = trainer.evaluate(tokenized[\"test\"])\n","print(metrics)\n"],"metadata":{"id":"3ZHhYY4ZUhsQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample = tokenized[\"test\"].select(range(5))\n","inputs  = tokenizer(sample[\"input_text\"], return_tensors=\"pt\", truncation=True).to(model.device)\n","outs    = model.generate(**inputs, max_length=128)\n","print(tokenizer.batch_decode(outs, skip_special_tokens=True))"],"metadata":{"id":"xVxYXbUNZ9lp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1. Grab 5 raw examples\n","sample = data[\"test\"].select(range(5))\n","\n","# 2. Tokenize on the fly (so you still have the raw text)\n","encoded = tokenizer(\n","    sample[\"input_text\"],\n","    return_tensors=\"pt\",\n","    truncation=True,\n","    padding=True\n",").to(model.device)\n","\n","# 3. Generate summaries+keywords\n","outs = model.generate(**encoded, max_length=128)\n","\n","# 4. Decode and print\n","print(tokenizer.batch_decode(outs, skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-_9ayI1TaLcH","executionInfo":{"status":"ok","timestamp":1745189654799,"user_tz":240,"elapsed":2556,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"66560386-079c-4c67-8587-8670a3a4fac1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['The health inspection revealed that the food storage area was not properly elevated, and there were crates used for food storage in the dry food storage area and the walk-in cooler needed proper shelving units. While these violations indicate some concerns about food safety practices, they do not pose an immediate health risk, so it may still be safe to eat there, but consumers should be aware of these issues. **Keywords:** food storage, crates, food storage, health inspection, safety.', 'The health inspection revealed several serious violations, including a partially smoked condiment on the cutting board, a rusty jar of meat, and a leaking faucet in the butcher prep area. While these issues indicate some concerns about food safety, they do not pose an immediate health risk, making it generally safe to eat there, but consumers should be aware of these issues. **Keywords:** food safety, smoking, condiment, cleanliness, health inspection, violations.', 'The health inspection revealed several violations, including a gap in the delivery door, damaged door handles, and a leaky faucet in the kitchen, which could pose a risk to food safety. While these violations indicate some concerns about cleanliness and maintenance, they do not pose an immediate health risk, making it generally safe to eat there, but consumers should be aware of these issues. **Keywords:** pest control, food safety, maintenance, plumbing, plumbing, health inspection.', 'The health inspection revealed several serious violations, including the absence of hand soap in the washrooms, a broken gasket in the cooler, and a leak in the kitchen sink. While these issues indicate some concerns about cleanliness and maintenance, they do not pose an immediate health risk, making it generally safe to eat there, but consumers should be aware of these issues. **Keywords:** hand soap, food contact surfaces, maintenance, cleanliness, safety, inspection.', 'The health inspection revealed several cleanliness and maintenance issues, including improper storage of unclean items, improper storage of food contact surfaces, and improper maintenance of floors and walls. While these violations indicate some concerns about food safety practices, they do not pose an immediate health risk, making it generally safe to eat there, but consumers should be aware of these issues. **Keywords:** cleanliness, food safety, maintenance, cleanliness, food contact surfaces, health inspection.']\n"]}]},{"cell_type":"code","source":["# 1. Grab 5 raw examples\n","sample = data[\"test\"].select(range(5))\n","\n","# 2. Inference & post‑processing\n","def clean_output(raw: str):\n","    # split summary vs keywords\n","    parts = raw.split(\"Keywords:\")\n","    summary = parts[0].replace(\"Summary:\", \"\").strip().rstrip(\".\")\n","    kw_part = parts[1] if len(parts)>1 else \"\"\n","    # dedupe & normalize keywords\n","    kws = [k.strip().lower() for k in kw_part.split(\",\") if k.strip()]\n","    kws = list(dict.fromkeys(kws))\n","    return summary, kws\n","\n","# 3. Tokenize & generate\n","encoded = tokenizer(\n","    sample[\"input_text\"],\n","    return_tensors=\"pt\",\n","    truncation=True,\n","    padding=True\n",").to(model.device)\n","outs = model.generate(**encoded, max_length=128)\n","\n","# 4. Decode + clean\n","decoded = tokenizer.batch_decode(outs, skip_special_tokens=True)\n","for i, raw in enumerate(decoded):\n","    summary, keywords = clean_output(raw)\n","    print(f\"Example {i+1}:\\n • Summary: {summary}\\n • Keywords: {keywords}\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5LX-Cf1qb8Qf","executionInfo":{"status":"ok","timestamp":1745190119100,"user_tz":240,"elapsed":2510,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"731b3d1b-ad90-45ae-a0c1-df0a031294c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Example 1:\n"," • Summary: The health inspection revealed that the food storage area was not properly elevated, and there were crates used for food storage in the dry food storage area and the walk-in cooler needed proper shelving units. While these violations indicate some concerns about food safety practices, they do not pose an immediate health risk, so it may still be safe to eat there, but consumers should be aware of these issues. **\n"," • Keywords: ['** food storage', 'crates', 'food storage', 'health inspection', 'safety.']\n","\n","Example 2:\n"," • Summary: The health inspection revealed several serious violations, including a partially smoked condiment on the cutting board, a rusty jar of meat, and a leaking faucet in the butcher prep area. While these issues indicate some concerns about food safety, they do not pose an immediate health risk, making it generally safe to eat there, but consumers should be aware of these issues. **\n"," • Keywords: ['** food safety', 'smoking', 'condiment', 'cleanliness', 'health inspection', 'violations.']\n","\n","Example 3:\n"," • Summary: The health inspection revealed several violations, including a gap in the delivery door, damaged door handles, and a leaky faucet in the kitchen, which could pose a risk to food safety. While these violations indicate some concerns about cleanliness and maintenance, they do not pose an immediate health risk, making it generally safe to eat there, but consumers should be aware of these issues. **\n"," • Keywords: ['** pest control', 'food safety', 'maintenance', 'plumbing', 'health inspection.']\n","\n","Example 4:\n"," • Summary: The health inspection revealed several serious violations, including the absence of hand soap in the washrooms, a broken gasket in the cooler, and a leak in the kitchen sink. While these issues indicate some concerns about cleanliness and maintenance, they do not pose an immediate health risk, making it generally safe to eat there, but consumers should be aware of these issues. **\n"," • Keywords: ['** hand soap', 'food contact surfaces', 'maintenance', 'cleanliness', 'safety', 'inspection.']\n","\n","Example 5:\n"," • Summary: The health inspection revealed several cleanliness and maintenance issues, including improper storage of unclean items, improper storage of food contact surfaces, and improper maintenance of floors and walls. While these violations indicate some concerns about food safety practices, they do not pose an immediate health risk, making it generally safe to eat there, but consumers should be aware of these issues. **\n"," • Keywords: ['** cleanliness', 'food safety', 'maintenance', 'cleanliness', 'food contact surfaces', 'health inspection.']\n","\n"]}]},{"cell_type":"code","source":["import re\n","\n","def clean_output(raw: str):\n","    # remove any ** markers\n","    raw = raw.replace(\"**\", \"\")\n","    # split summary vs keywords\n","    parts = re.split(r\"Keywords?:\", raw, maxsplit=1)\n","    summary = parts[0].replace(\"Summary:\", \"\").strip().rstrip(\".\")\n","    # ditch the boilerplate sentence starting with “While”\n","    summary = re.sub(r\"\\bWhile.*$\", \"\", summary).strip().rstrip(\".\")\n","    # extract & dedupe keywords\n","    kw_part = parts[1] if len(parts)>1 else \"\"\n","    kws = [k.strip().lower().rstrip(\".\") for k in kw_part.split(\",\") if k.strip()]\n","    kws = list(dict.fromkeys(kws))\n","    return summary, kws\n","\n","# Test again:\n","decoded = tokenizer.batch_decode(outs, skip_special_tokens=True)\n","for i, raw in enumerate(decoded,1):\n","    s, k = clean_output(raw)\n","    print(f\"Example {i}:\\n • Summary: {s}\\n • Keywords: {k}\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vX7WHOjccH8l","executionInfo":{"status":"ok","timestamp":1745190164267,"user_tz":240,"elapsed":10,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"9e6c0786-b8cc-4837-907f-08d5b5440fd0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Example 1:\n"," • Summary: The health inspection revealed that the food storage area was not properly elevated, and there were crates used for food storage in the dry food storage area and the walk-in cooler needed proper shelving units\n"," • Keywords: ['food storage', 'crates', 'health inspection', 'safety']\n","\n","Example 2:\n"," • Summary: The health inspection revealed several serious violations, including a partially smoked condiment on the cutting board, a rusty jar of meat, and a leaking faucet in the butcher prep area\n"," • Keywords: ['food safety', 'smoking', 'condiment', 'cleanliness', 'health inspection', 'violations']\n","\n","Example 3:\n"," • Summary: The health inspection revealed several violations, including a gap in the delivery door, damaged door handles, and a leaky faucet in the kitchen, which could pose a risk to food safety\n"," • Keywords: ['pest control', 'food safety', 'maintenance', 'plumbing', 'health inspection']\n","\n","Example 4:\n"," • Summary: The health inspection revealed several serious violations, including the absence of hand soap in the washrooms, a broken gasket in the cooler, and a leak in the kitchen sink\n"," • Keywords: ['hand soap', 'food contact surfaces', 'maintenance', 'cleanliness', 'safety', 'inspection']\n","\n","Example 5:\n"," • Summary: The health inspection revealed several cleanliness and maintenance issues, including improper storage of unclean items, improper storage of food contact surfaces, and improper maintenance of floors and walls\n"," • Keywords: ['cleanliness', 'food safety', 'maintenance', 'food contact surfaces', 'health inspection']\n","\n"]}]},{"cell_type":"code","source":["def summarize_violation(text):\n","    # tokenize & generate\n","    encoded = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n","    raw     = tokenizer.decode(model.generate(**encoded, max_length=128)[0], skip_special_tokens=True)\n","    # clean & return\n","    summary, keywords = clean_output(raw)\n","    return summary, keywords\n"],"metadata":{"id":"a7dVQ5mccbU0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ───── New Cell: Inference & Inspection ─────\n","\n","# 1. Grab 10 random examples from the test split via Dataset.shuffle().select()\n","sampled = data[\"test\"].shuffle(seed=42).select(range(10))\n","\n","# 2. Run them through your summarize_violation() helper\n","for ex in sampled:\n","    summary, keywords = summarize_violation(ex[\"input_text\"])\n","    print(f\"- Summary: {summary}\\n  Keywords: {keywords}\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2reud9teb8w","executionInfo":{"status":"ok","timestamp":1745190784926,"user_tz":240,"elapsed":18162,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"4533cb4a-a0d6-450d-de70-d9c83aabee19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["- Summary: The health inspection revealed several significant violations, including the absence of a handwashing sink at the pizza prep station, the presence of a high temperature dish machine, and cleanliness issues with food contact surfaces. Given these issues, it may not be safe to eat there until these issues are resolved\n","  Keywords: ['handwashing sink', 'temperature violation', 'food contact surfaces', 'cleanliness', 'inspection']\n","\n","- Summary: The health inspection revealed several cleanliness and maintenance issues, including a buildup of debris under the metal shelving, dust buildup on non-cooking equipment, and food spillage and debris on the cooking units\n","  Keywords: ['cleanliness', 'food safety', 'maintenance']\n","\n","- Summary: The health inspection revealed several violations, including dirty floors, damaged floor tiles, and missing wall bases, which could pose a risk to food safety\n","  Keywords: ['cleanliness', 'maintenance', 'food safety', 'inspection violations', 'health inspection']\n","\n","- Summary: The health inspection revealed several cleanliness and maintenance issues, including dirty coolers, floors, and walls, which need to be cleaned and repaired at all times\n","  Keywords: ['cleanliness', 'food safety', 'maintenance', 'health inspection', 'safety']\n","\n","- Summary: The health inspection revealed that the establishment needs to improve cleanliness and maintenance of floors, walls, and equipment, including the use of cleaning tools and equipment\n","  Keywords: ['cleanliness', 'maintenance', 'floors', 'walls', 'equipment', 'health inspection', 'safety']\n","\n","- Summary: The health inspection revealed several serious violations, including the absence of a previous summary report, the absence of a recent report, and the cleanliness of the storage areas and storage areas. Given these issues, it may not be safe to eat there until these violations are addressed\n","  Keywords: ['health inspection', 'food safety', 'cleanliness', 'storage', 'maintenance', 'violations', 'safety']\n","\n","- Summary: The health authority deemed the previous minor violations to be a separate and distinct offense, and a serious violation was deemed to have been committed\n","  Keywords: ['minor violations', 'health authority', 'health inspection', 'violation', 'serious violation']\n","\n","- Summary: The health inspection revealed several serious violations, including the need to repair the floor openings in the dining room, repair damaged walls in the kitchen, and repair the ceilings in the gym\n","  Keywords: ['serious violations', 'floor openings', 'maintenance', 'health inspection', 'violations']\n","\n","- Summary: The health inspection revealed several critical violations, including the lack of proper sanitizing equipment, inadequate hand sinks, and dirty food storage areas. Given these critical issues, it may not be safe to eat there until they are resolved\n","  Keywords: ['sanitizing equipment', 'hand sinks', 'food storage', 'cleanliness', 'safety']\n","\n","- Summary: The health inspection revealed multiple critical violations, including the absence of hot water at the time of the inspection, the absence of a certified food manager, and the cleanliness of food contact surfaces\n","  Keywords: ['hot water', 'certified food manager', 'food safety', 'cleanliness', 'health inspection', 'violations']\n","\n"]}]},{"cell_type":"markdown","source":["Evaluation"],"metadata":{"id":"RoRayw0RLe1H"}},{"cell_type":"code","source":["# Install the evaluate library\n","!pip install evaluate --quiet\n","!pip install rouge_score --quiet\n","\n","import evaluate\n","\n","# Load ROUGE metric\n","rouge = evaluate.load(\"rouge\")\n","\n","# Prepare test subset and references\n","subset = data[\"test\"].shuffle(seed=42).select(range(300))\n","refs = [\n","    ex[\"target_text\"].split(\"Keywords:\")[0]\n","        .replace(\"Summary:\", \"\")\n","        .strip()\n","    for ex in subset\n","]\n","\n","# Batch-generate predictions\n","texts = [ex[\"input_text\"] for ex in subset]\n","preds = []\n","batch_size = 32  # adjust based on GPU memory\n","\n","for i in range(0, len(texts), batch_size):\n","    batch = texts[i : i + batch_size]\n","    enc = tokenizer(\n","        batch,\n","        return_tensors=\"pt\",\n","        truncation=True,\n","        padding=True\n","    ).to(model.device)\n","\n","    out = model.generate(**enc, max_length=128)\n","    dec = tokenizer.batch_decode(out, skip_special_tokens=True)\n","\n","    # Extract only the summary portion\n","    cleaned = [\n","        raw.split(\"Keywords:\")[0].replace(\"Summary:\", \"\").strip()\n","        for raw in dec\n","    ]\n","    preds.extend(cleaned)\n","\n","# Compute ROUGE\n","results = rouge.compute(predictions=preds, references=refs)\n","print(results)\n","\n","# Why this is faster:\n","# - Generates multiple samples per generate() call\n","# - Reduces Python loop overhead\n","# - Executes in seconds instead of minutes\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LwaU8gzwftY7","executionInfo":{"status":"ok","timestamp":1745193316614,"user_tz":240,"elapsed":32890,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"61048f8c-d779-4910-ab16-871c6f3e046c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'rouge1': np.float64(0.5647419955074559), 'rouge2': np.float64(0.33582642641399674), 'rougeL': np.float64(0.4810599358816067), 'rougeLsum': np.float64(0.4815245282645666)}\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","# 1. Prepare test subset and ground‑truth keyword sets\n","subset = data[\"test\"].shuffle(seed=42).select(range(300))\n","refs_kw = [\n","    {k.strip().lower().rstrip(\".\") for k in ex[\"target_text\"].split(\"Keywords:\")[1].split(\",\")}\n","    for ex in subset\n","]\n","\n","# 2. Batch‑generate predictions\n","texts = [ex[\"input_text\"] for ex in subset]\n","preds_kw = []\n","batch_size = 32\n","\n","for i in range(0, len(texts), batch_size):\n","    batch_texts = texts[i : i + batch_size]\n","    enc = tokenizer(\n","        batch_texts,\n","        return_tensors=\"pt\",\n","        truncation=True,\n","        padding=True\n","    ).to(model.device)\n","\n","    outs = model.generate(**enc, max_length=128)\n","    dec = tokenizer.batch_decode(outs, skip_special_tokens=True)\n","\n","    # parse keywords out of each generated string\n","    for raw in dec:\n","        # same splitting logic you used before\n","        kw_part = raw.split(\"Keywords:\")[1] if \"Keywords:\" in raw else \"\"\n","        kws = [k.strip().lower().rstrip(\".\") for k in kw_part.split(\",\") if k.strip()]\n","        preds_kw.append(set(dict.fromkeys(kws)))  # dedupe\n","\n","# 3. Compute precision, recall, F1\n","precisions, recalls, f1s = [], [], []\n","for r, p in zip(refs_kw, preds_kw):\n","    if not r or not p:\n","        continue\n","    tp = len(r & p)\n","    prec = tp / len(p)\n","    rec  = tp / len(r)\n","    f1   = 2 * prec * rec / (prec + rec) if (prec+rec)>0 else 0\n","    precisions.append(prec)\n","    recalls.append(rec)\n","    f1s.append(f1)\n","\n","print(\"Keyword P:\", np.mean(precisions))\n","print(\"Keyword R:\", np.mean(recalls))\n","print(\"Keyword F1:\", np.mean(f1s))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oYfUnb2PhpQD","executionInfo":{"status":"ok","timestamp":1745193351531,"user_tz":240,"elapsed":26429,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"ecf83fda-cc0b-452e-b297-185784df5251"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Keyword P: 0.44911904761904764\n","Keyword R: 0.4006190476190476\n","Keyword F1: 0.42101927701927705\n"]}]},{"cell_type":"code","source":["!pip install tqdm --quiet\n","from tqdm.auto import tqdm\n","import numpy as np\n","\n","# Prepare test subset (you can change 100→300 when you want full eval)\n","subset = data[\"test\"].shuffle(seed=42).select(range(100))\n","\n","# Ground‑truth keyword sets\n","refs_kw = [\n","    {k.strip().lower().rstrip(\".\") for k in ex[\"target_text\"].split(\"Keywords:\")[1].split(\",\")}\n","    for ex in subset\n","]\n","\n","# Inference + collection\n","preds_kw = []\n","for ex in tqdm(subset, desc=\"Generating keywords\"):\n","    s, kws = summarize_violation_limit5(ex[\"input_text\"])\n","    preds_kw.append(kws)\n","\n","# Compute P/R/F1\n","precisions, recalls, f1s = [], [], []\n","for r, p in zip(refs_kw, preds_kw):\n","    if not r or not p:\n","        continue\n","    tp = len(r & p)\n","    prec = tp/len(p)\n","    rec  = tp/len(r)\n","    f1   = 2*prec*rec/(prec+rec) if (prec+rec)>0 else 0\n","    precisions.append(prec); recalls.append(rec); f1s.append(f1)\n","\n","print(f\"\\nKeyword P: {np.mean(precisions):.3f}\")\n","print(f\"Keyword R: {np.mean(recalls):.3f}\")\n","print(f\"Keyword F1: {np.mean(f1s):.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":243,"referenced_widgets":["76a218d824dd4696b1530f5ad24f2a27","458052c39b5b4a89b755249808bb5091","6ff2797a721f4f1d9338d914dbf2e9c4","0a16365756f842d981bce481e49e1dc7","27c98b46bb4c4fa698e20c0a5806872b","0b8fde468e504409a71dde98f9c1747c","15418d029e7844eaa08a55d631c0f405","a4248510155245ecaf5945a76c3f6d5f","f7ec2b08023d45af9be3828585df65f3","147a4b0852dd4f9699353ef63da3d8e9","3b82fa9acafa44e6a9bdcb11b873f464"]},"id":"PwX_6AF_ixl1","executionInfo":{"status":"error","timestamp":1745192133915,"user_tz":240,"elapsed":3890,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"a9fd3ef8-94c8-45bf-f6a5-30a4ee88e476"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Generating keywords:   0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76a218d824dd4696b1530f5ad24f2a27"}},"metadata":{}},{"output_type":"error","ename":"ValueError","evalue":"too many values to unpack (expected 2)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-a09bcec7e707>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mpreds_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Generating keywords\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_violation_limit5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mpreds_kw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}]},{"cell_type":"code","source":["# 1. Update your helper to return both summary & keywords\n","def summarize_violation_limit5(text):\n","    instruction = (\n","        \"Summarize this violation in one concise sentence (no boilerplate). \"\n","        \"Then list exactly the top 5 most important keywords. \"\n","        \"Format: Summary: ... Keywords: kw1, kw2, kw3, kw4, kw5\"\n","    )\n","    prompt = instruction + \"\\n\\nViolation:\\n\" + text\n","\n","    enc = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n","    out = model.generate(**enc, max_length=128)\n","    raw = tokenizer.decode(out[0], skip_special_tokens=True)\n","\n","    # split summary vs keywords\n","    parts = raw.split(\"Keywords:\")\n","    summary = parts[0].replace(\"Summary:\", \"\").strip().rstrip(\".\")\n","    kw_part = parts[1] if len(parts)>1 else \"\"\n","    kws = [k.strip().lower().rstrip(\".\") for k in kw_part.split(\",\") if k.strip()]\n","    # enforce exactly 5 slots\n","    kws = (kws + [\"\"]*5)[:5]\n","    return summary, set(kws)\n","\n","# 2. Install & import tqdm (if you haven't already)\n","!pip install tqdm --quiet\n","from tqdm.auto import tqdm\n","import numpy as np\n","\n","# 3. Prepare test subset and ground truth\n","subset = data[\"test\"].shuffle(seed=42).select(range(100))\n","refs_kw = [\n","    {k.strip().lower().rstrip(\".\") for k in ex[\"target_text\"].split(\"Keywords:\")[1].split(\",\")}\n","    for ex in subset\n","]\n","\n","# 4. Loop with progress bar\n","preds_kw = []\n","for ex in tqdm(subset, desc=\"Evaluating keywords\"):\n","    _, kws = summarize_violation_limit5(ex[\"input_text\"])\n","    preds_kw.append(kws)\n","\n","# 5. Compute P/R/F1\n","precisions, recalls, f1s = [], [], []\n","for r, p in zip(refs_kw, preds_kw):\n","    if not r or not p:\n","        continue\n","    tp = len(r & p)\n","    prec = tp/len(p)\n","    rec  = tp/len(r)\n","    f1   = 2*prec*rec/(prec+rec) if (prec+rec)>0 else 0\n","    precisions.append(prec); recalls.append(rec); f1s.append(f1)\n","\n","print(f\"\\nKeyword P: {np.mean(precisions):.3f}\")\n","print(f\"Keyword R: {np.mean(recalls):.3f}\")\n","print(f\"Keyword F1: {np.mean(f1s):.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["b410ed94553747f5b813b53b55030dad","965aaf4a140646a8955237cf62415311","973e2aa7cdcd48df8c1d4fe3932b7d7c","c28a49a58f514a4b816228a340de5d78","c30f7c672e584186ac30de1c0def09e4","26a2e2eec5794149a0540c0f1b5c2007","35ebaea463934cc1aaafb7d54fae9675","b9efd140164641f181a4a14258c22de3","4a11508c91d444c1ad4b7db2278dd61a","7cd29a96088541cba6838cb15df8f5ea","49320578df8a41e4a56e621db982c8cf"]},"id":"MYZ1xsx_j0Ga","executionInfo":{"status":"ok","timestamp":1745192323521,"user_tz":240,"elapsed":146984,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"3b4f40e7-facf-4ea0-fd82-6e71b3b1c3a9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Evaluating keywords:   0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b410ed94553747f5b813b53b55030dad"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Keyword P: 0.324\n","Keyword R: 0.242\n","Keyword F1: 0.275\n"]}]},{"cell_type":"code","source":["from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n","\n","# 1. Define your updated training arguments\n","new_args = Seq2SeqTrainingArguments(\n","    output_dir=\"flan_t5_finetuned\",\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_loss\",\n","    num_train_epochs=1,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    learning_rate=2e-5,\n","    predict_with_generate=True,\n","    report_to=\"none\",\n",")\n","\n","# 2. Re‑instantiate the Trainer with the same model, data, collator, but new args:\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=new_args,\n","    train_dataset=tokenized[\"train\"],\n","    eval_dataset=tokenized[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n",")\n","\n","# 3. Run the light retrain\n","trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"id":"bVqThcRVkvA9","executionInfo":{"status":"ok","timestamp":1745192831114,"user_tz":240,"elapsed":107286,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"7328357c-e56d-4a84-dbdf-0ef178f4922c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-32-d5c1a20efaa5>:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n","  trainer = Seq2SeqTrainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 01:46, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.898057</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=300, training_loss=1.0952212524414062, metrics={'train_runtime': 106.8609, 'train_samples_per_second': 22.459, 'train_steps_per_second': 2.807, 'total_flos': 1634890276970496.0, 'train_loss': 1.0952212524414062, 'epoch': 1.0})"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["model.save_pretrained(\"flan_t5_finetuned_final\")\n","tokenizer.save_pretrained(\"flan_t5_finetuned_final\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRtpYaMEoea6","executionInfo":{"status":"ok","timestamp":1745193480247,"user_tz":240,"elapsed":2055,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"aa864615-e944-4170-f44d-5e6b1ba9038d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('flan_t5_finetuned_final/tokenizer_config.json',\n"," 'flan_t5_finetuned_final/special_tokens_map.json',\n"," 'flan_t5_finetuned_final/spiece.model',\n"," 'flan_t5_finetuned_final/added_tokens.json',\n"," 'flan_t5_finetuned_final/tokenizer.json')"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["# 1. Zip the folder containing your model & tokenizer\n","!zip -r flan_t5_finetuned_final.zip flan_t5_finetuned_final\n","\n","# 2. Download the zip file to your local machine\n","from google.colab import files\n","files.download('flan_t5_finetuned_final.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156},"id":"R4IH8MPLpUsj","executionInfo":{"status":"ok","timestamp":1745193675624,"user_tz":240,"elapsed":55240,"user":{"displayName":"Zahid Rahman","userId":"08305003582771355304"}},"outputId":"596d3554-b5a6-49cd-ddfd-f7b4ab52bd9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: flan_t5_finetuned_final/ (stored 0%)\n","  adding: flan_t5_finetuned_final/tokenizer_config.json (deflated 95%)\n","  adding: flan_t5_finetuned_final/model.safetensors (deflated 7%)\n","  adding: flan_t5_finetuned_final/special_tokens_map.json (deflated 85%)\n","  adding: flan_t5_finetuned_final/config.json (deflated 62%)\n","  adding: flan_t5_finetuned_final/spiece.model (deflated 48%)\n","  adding: flan_t5_finetuned_final/tokenizer.json (deflated 74%)\n","  adding: flan_t5_finetuned_final/generation_config.json (deflated 29%)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_2bc54a0f-18d8-4c2c-ba84-5bc5e7d2b615\", \"flan_t5_finetuned_final.zip\", 919245084)"]},"metadata":{}}]},{"cell_type":"code","source":["# Need to do Qualitative Evaluation"],"metadata":{"id":"d1cNoMHdMBP_"},"execution_count":null,"outputs":[]}]}